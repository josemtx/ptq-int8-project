{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9f63ea",
   "metadata": {},
   "source": [
    "# Calibración y heurísticas\n",
    "Este cuaderno documenta:\n",
    "- `calibrate_weights_greedy`: selección por capa de (per-tensor/per-channel) × (simétrica/asimétrica) minimizando error local.\n",
    "- `tune_percentiles_SA`: enfriamiento simulado para afinar percentiles de activación por capa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6a8b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta raíz añadida a sys.path → c:\\Users\\josem\\Desktop\\EL AÑO\\OH\\ptq-int8-project\n"
     ]
    }
   ],
   "source": [
    "# --- Setup rápido para importar src.* desde notebooks/ ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Sube hasta encontrar la carpeta raíz del repo (la que contiene src/)\n",
    "ROOT = Path.cwd()\n",
    "while not (ROOT / \"src\").exists() and ROOT.parent != ROOT:\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "sys.path.insert(0, str(ROOT))\n",
    "print(\"Ruta raíz añadida a sys.path →\", ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6890320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- src.calibrator.calibrate_weights_greedy ---\n",
      "def calibrate_weights_greedy(m, Xcal, max_samples=256):\n",
      "    X = Xcal[:max_samples]\n",
      "    inter = forward_intermediates(m, X)\n",
      "    best = {}\n",
      "    for layer in [\"c1\",\"c2\",\"fc1\",\"fc2\"]:\n",
      "        W = getattr(m, layer).W\n",
      "        candidates = [(\"per_channel\", True), (\"per_tensor\", True), (\"per_tensor\", False)]\n",
      "        best_err, best_q = 1e30, None\n",
      "        for scheme, sym in candidates:\n",
      "            q = fit_weight_qparams(W, scheme=scheme, symmetric=sym)\n",
      "            if layer == \"c1\":\n",
      "                qs = QSimConvReLU(W, getattr(m, layer).b, q,\n",
      "                                  fit_act_qparams(inter[\"inp\"]),  # in\n",
      "                                  fit_act_qparams(inter[\"a1\"]))   # out\n",
      "                y_hat = qs.forward(inter[\"inp\"]);  y_ref = inter[\"a1\"]\n",
      "            elif layer == \"c2\":\n",
      "                qs = QSimConvReLU(W, getattr(m, layer).b, q,\n",
      "                                  fit_act_qparams(inter[\"p1\"]),   # <-- in correcto (post-pool)\n",
      "                                  fit_act_qparams(inter[\"a2\"]))   # out\n",
      "                y_hat = qs.forward(inter[\"p1\"]);   y_ref = inter[\"a2\"]\n",
      "            elif layer == \"fc1\":\n",
      "                qs = QSimLinear(W, getattr(m, layer).b, q,\n",
      "                                fit_act_qparams(inter[\"flat\"]),\n",
      "                                fit_act_qparams(inter[\"a3\"]))\n",
      "                y_hat = qs.forward(inter[\"flat\"]); y_ref = inter[\"a3\"]\n",
      "            else:  # fc2\n",
      "                qs = QSimLinear(W, getattr(m, layer).b, q,\n",
      "                                fit_act_qparams(inter[\"a3\"]),\n",
      "                                fit_act_qparams(inter[\"logits\"], symmetric=True, signed=True))\n",
      "                y_hat = qs.forward(inter[\"a3\"]);  y_ref = inter[\"logits\"]\n",
      "            err = float(np.mean((y_ref - y_hat) ** 2))\n",
      "            if err < best_err: best_err, best_q = err, q\n",
      "        best[layer] = best_q\n",
      "    return best\n",
      "\n",
      "--- src.calibrator.init_activation_qparams ---\n",
      "def init_activation_qparams(m, Xcal, p=99.0):\n",
      "    inter = forward_intermediates(m, Xcal)\n",
      "    aq = {}\n",
      "    aq[\"inp\"]  = fit_act_qparams(inter[\"inp\"],  method=\"percentile\", p=p, symmetric=False, signed=False)\n",
      "    aq[\"a1\"]   = fit_act_qparams(inter[\"a1\"],   method=\"percentile\", p=p, symmetric=False, signed=False)\n",
      "    aq[\"p1\"]   = fit_act_qparams(inter[\"p1\"],   method=\"percentile\", p=p, symmetric=False, signed=False)  # <- NUEVO\n",
      "    aq[\"a2\"]   = fit_act_qparams(inter[\"a2\"],   method=\"percentile\", p=p, symmetric=False, signed=False)\n",
      "    aq[\"flat\"] = fit_act_qparams(inter[\"flat\"], method=\"percentile\", p=p, symmetric=False, signed=False)\n",
      "    aq[\"a3\"]   = fit_act_qparams(inter[\"a3\"],   method=\"percentile\", p=p, symmetric=False, signed=False)\n",
      "    aq[\"out\"]  = fit_act_qparams(inter[\"logits\"], method=\"percentile\", p=p, symmetric=True,  signed=True)\n",
      "    return aq\n",
      "\n",
      "--- src.calibrator.tune_percentiles_SA ---\n",
      "def tune_percentiles_SA(m, wq, Xcal, Xval, Yval, acc_fp32, iters=60, p0=99.0, step=0.7):\n",
      "    rng = np.random.default_rng(0)\n",
      "    aq = init_activation_qparams(m, Xcal, p=p0)\n",
      "    inter = forward_intermediates(m, Xcal)  # cache\n",
      "\n",
      "    src_map = {\"inp\":\"inp\",\"a1\":\"a1\",\"p1\":\"p1\",\"a2\":\"a2\",\"flat\":\"flat\",\"a3\":\"a3\",\"out\":\"logits\"}\n",
      "\n",
      "    def rebuild(aq_in):\n",
      "        b = {}\n",
      "        for k, src in src_map.items():\n",
      "            sym = (k == \"out\"); signed = sym\n",
      "            b[k] = fit_act_qparams(inter[src], method=\"percentile\", p=aq_in[k][\"p\"],\n",
      "                                   symmetric=sym, signed=signed)\n",
      "        return b\n",
      "\n",
      "    def eval_acc(aq_in):\n",
      "        qs = build_qsim_blocks(m, wq, aq_in)\n",
      "        y  = predict_qsim(m, qs, Xval)\n",
      "        return (y == Yval).mean() * 100.0\n",
      "\n",
      "    best = aq.copy(); best_acc = curr_acc = eval_acc(aq)\n",
      "    T = 1.0\n",
      "    for _ in range(iters):\n",
      "        cand = {k: v.copy() for k, v in aq.items()}\n",
      "        for k in cand:\n",
      "            cand[k][\"p\"] = float(np.clip(cand[k][\"p\"] + rng.uniform(-step, step), 90.0, 99.9))\n",
      "        cand = rebuild(cand)\n",
      "        a = eval_acc(cand)\n",
      "        # restricción dura: no aceptar candidatos que caigan >2 pts vs FP32\n",
      "        if (acc_fp32 - a) <= 2.0 and (a > curr_acc or np.exp((a - curr_acc) / max(T, 1e-8)) > rng.uniform()):\n",
      "            aq, curr_acc = cand, a\n",
      "            if a > best_acc:\n",
      "                best, best_acc = cand, a\n",
      "        T = max(T * 0.95, 1e-3)\n",
      "    return best\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect, textwrap\n",
    "from src.calibrator import calibrate_weights_greedy, init_activation_qparams, tune_percentiles_SA\n",
    "\n",
    "def show(fn):\n",
    "    print(f\"--- {fn.__module__}.{fn.__name__} ---\")\n",
    "    print(textwrap.dedent(inspect.getsource(fn)))\n",
    "\n",
    "show(calibrate_weights_greedy)\n",
    "show(init_activation_qparams)\n",
    "show(tune_percentiles_SA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42c902",
   "metadata": {},
   "source": [
    "## 1) Greedy por capa\n",
    "Idea: para **cada capa** probamos combinaciones de esquema y simetría, cuantizamos pesos y medimos **error local** (p.ej. MSE entre salida FP32 y QSim de la capa con datos de calibración). Elegimos la que **minimiza** ese error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293c00ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'scheme': 'per_tensor', 'symmetric': True}, 2575.445068359375)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.quantizer import fit_weight_qparams, quantize_weights\n",
    "\n",
    "# supongamos pesos sintéticos de una \"capa\"\n",
    "W = np.random.randn(4, 4, 3, 3).astype(np.float32)\n",
    "\n",
    "cands = [\n",
    "    dict(scheme=\"per_tensor\",  symmetric=True),\n",
    "    dict(scheme=\"per_tensor\",  symmetric=False),\n",
    "    dict(scheme=\"per_channel\", symmetric=True),\n",
    "    dict(scheme=\"per_channel\", symmetric=False),\n",
    "]\n",
    "\n",
    "def fake_layer_mse(W_fp32, W_q):\n",
    "    # Ejemplo: error de reconstrucción de pesos como proxy (ilustrativo)\n",
    "    return float(np.mean((W_fp32 - W_q.astype(np.float32))**2))\n",
    "\n",
    "best, best_err = None, 1e9\n",
    "for C in cands:\n",
    "    qparams = fit_weight_qparams(W, scheme=C[\"scheme\"], symmetric=C[\"symmetric\"])\n",
    "    Wq = quantize_weights(W, qparams)\n",
    "    err = fake_layer_mse(W, Wq)\n",
    "    if err < best_err:\n",
    "        best, best_err = C, err\n",
    "\n",
    "best, best_err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c401bb",
   "metadata": {},
   "source": [
    "## 2) Percentiles de activación y SA\n",
    "- Inicializamos percentiles (p.ej., p=99) por capa.\n",
    "- Definimos un **vecindario** (p ± Δ).\n",
    "- Con **enfriamiento** vamos aceptando candidatos que **mejoran** métrica global (validación) y, a temperatura alta, permitimos empeoramientos pequeños para escapar de óptimos locales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd090712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.4798070991393, 99.99959224675483)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def metric(p):\n",
    "    # métrica sintética (máximo cerca de p* ~ 97.5)\n",
    "    return -((p - 97.5)**2) + 100\n",
    "\n",
    "p = 99.0\n",
    "T = 2.0\n",
    "best = (p, metric(p))\n",
    "rng = np.random.default_rng(0)\n",
    "for it in range(20):\n",
    "    cand = p + rng.normal(0, 0.7)   # vecino\n",
    "    m_cur, m_cand = metric(p), metric(cand)\n",
    "    if (m_cand > m_cur) or (np.exp((m_cand - m_cur)/max(T,1e-6)) > rng.random()):\n",
    "        p = cand\n",
    "    if metric(p) > best[1]:\n",
    "        best = (p, metric(p))\n",
    "    T *= 0.95\n",
    "\n",
    "best  # p cercano a ~97.5 en esta demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f3946",
   "metadata": {},
   "source": [
    "## 3) Relación con la memoria\n",
    "- §3 *Implementación*: Algoritmos de calibración (`CALIBRATE_WEIGHTS`, `CALIBRATE_ACTS_SA`) que aquí hemos comentado paso a paso.\n",
    "- §4 *Experimentos*: el ajuste por SA (Tabla de ablación) explica la recuperación de precisión frente a p fijo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
