{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ea0f41",
   "metadata": {},
   "source": [
    "# Cuantización afín y motor QSim\n",
    "Este cuaderno comenta y demuestra con **ejemplos mínimos**:\n",
    "- Ecuaciones de **cuantización afín** (§2) ↔ funciones de `src/quantizer.py`.\n",
    "- **Acumulación INT32** y **requant** (§3) ↔ `src/qsim_engine.py`.\n",
    "- **Fusión Conv+ReLU** en cuantizado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11bc381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta raíz añadida a sys.path → c:\\Users\\josem\\Desktop\\EL AÑO\\OH\\ptq-int8-project\n"
     ]
    }
   ],
   "source": [
    "# --- Setup rápido para importar src.* desde notebooks/ ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Sube hasta encontrar la carpeta raíz del repo (la que contiene src/)\n",
    "ROOT = Path.cwd()\n",
    "while not (ROOT / \"src\").exists() and ROOT.parent != ROOT:\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "sys.path.insert(0, str(ROOT))\n",
    "print(\"Ruta raíz añadida a sys.path →\", ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7635d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- src.quantizer.affine_params ---\n",
      "def affine_params(a, b, num_bits=8, symmetric=False, signed=False):\n",
      "    qmin, qmax = (-(2**(num_bits-1)), 2**(num_bits-1)-1) if signed else (0, 2**num_bits - 1)\n",
      "    # asegurar que 0 cae en [a,b]\n",
      "    a = min(a, 0.0); b = max(b, 0.0)\n",
      "    if symmetric:\n",
      "        m = max(abs(a), abs(b)); a, b = -m, m\n",
      "    # escala y zp\n",
      "    scale = (b - a) / (qmax - qmin) if b > a else 1.0\n",
      "    if signed:\n",
      "        zp = 0\n",
      "    else:\n",
      "        zp = round(qmin - a / scale)\n",
      "        zp = int(np.clip(zp, qmin, qmax))\n",
      "    return float(scale if scale != 0 else 1.0), int(zp), int(qmin), int(qmax)\n",
      "\n",
      "--- src.quantizer.quantize ---\n",
      "def quantize(x, scale, zp, qmin, qmax, dtype=np.int8):\n",
      "    q = np.round(x / scale + zp)\n",
      "    q = np.clip(q, qmin, qmax).astype(np.int32)\n",
      "    return q.astype(dtype)\n",
      "\n",
      "--- src.quantizer.dequantize ---\n",
      "def dequantize(q, scale, zp):\n",
      "    return scale * (q.astype(np.float32) - zp)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect, textwrap\n",
    "from src.quantizer import affine_params, quantize, dequantize, fit_weight_qparams, fit_act_qparams\n",
    "from src.qsim_engine import conv2d_int, linear_int, requantize_int32\n",
    "\n",
    "def show(fn):\n",
    "    print(f\"--- {fn.__module__}.{fn.__name__} ---\")\n",
    "    print(textwrap.dedent(inspect.getsource(fn)))\n",
    "    \n",
    "show(affine_params)\n",
    "show(quantize)\n",
    "show(dequantize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f570dcfd",
   "metadata": {},
   "source": [
    "# 1) Cuantización afín (Sección 2 de la memoria)\n",
    "\n",
    "**Ecuaciones**\n",
    "- $x_q = \\mathrm{clip}(\\mathrm{round}(x/s) + z,\\ q_{\\min}, q_{\\max})$\n",
    "- $x \\approx s \\cdot (x_q - z)$\n",
    "\n",
    "**Interpretación.** `affine_params` fija $s,z$ para un rango $[a,b]$, con variantes simétrica ($z{=}0$) o asimétrica. `quantize`/`dequantize` implementan exactamente esas dos ecuaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e757177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x   : [-1.2 -0.1  0.   0.3  1. ]\n",
      "x_q : [  0 127 139 174 255]\n",
      "x≈  : [-1.1992157  -0.10352941  0.          0.3019608   1.0007843 ]\n",
      "err : [0.0007844  0.00352941 0.         0.00196078 0.00078428]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([-1.2, -0.1, 0.0, 0.3, 1.0], dtype=np.float32)\n",
    "s, z, qmin, qmax = affine_params(a=float(x.min()), b=float(x.max()),\n",
    "                                 num_bits=8, symmetric=False, signed=False)\n",
    "xq = quantize(x, s, z, qmin, qmax, dtype=np.uint8)\n",
    "xr = dequantize(xq, s, z)\n",
    "print(\"x   :\", x)\n",
    "print(\"x_q :\", xq)\n",
    "print(\"x≈  :\", xr)\n",
    "print(\"err :\", np.abs(x - xr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f044846e",
   "metadata": {},
   "source": [
    "# 2) Recuantización tras la acumulación INT32 (Sección 2)\n",
    "\n",
    "Salida entera de la capa:\n",
    "$$\n",
    "y_q = \\mathrm{clip}\\!\\left(\\left\\lfloor y_{32}\\,\\frac{s_x s_w}{s_y} \\right\\rceil + z_y,\\ q_{\\min}, q_{\\max}\\right).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a464d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y32: [-1000   -10     0    15  1000]\n",
      "yq : [ 0 10 10 10 43]\n"
     ]
    }
   ],
   "source": [
    "y32 = np.array([-1000, -10, 0, 15, 1000], dtype=np.int32)\n",
    "s_x, s_w, s_y = 0.05, 0.02, 0.03\n",
    "z_y, qmin, qmax = 10, 0, 255\n",
    "yq = requantize_int32(y32, s_x, s_w, s_y, z_y, qmin, qmax, out_dtype=np.uint8)\n",
    "print(\"y32:\", y32)\n",
    "print(\"yq :\", yq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b04bf8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 3) Convolución INT8→INT32 y fusión ReLU (§2, §3)\n",
    "`conv2d_int` hace el producto sobre **enteros centrados** `(x_q - z_x)*(w_q - z_w)` y acumula en INT32.\n",
    "Después `requantize_int32` pasa a la salida cuantizada; la **ReLU** en cuantizado es `max(y_q, z_y)`.\n",
    "\n",
    "> Ejemplo mínimo con tensores pequeños (sin kernels externos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c91e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y32: [[[[-40]]]]\n",
      "yq (antes ReLU): [[[[9]]]]  yq_relu: [[[[10]]]]\n"
     ]
    }
   ],
   "source": [
    "# activación 1x1 con 1 canal y kernel 1x1 -> salida 1 canal\n",
    "xq = np.array([[[[120]]]], dtype=np.uint8)   # (N=1,C=1,H=1,W=1)\n",
    "wq = np.array([[[[5]]]], dtype=np.int8)      # (OC=1,IC=1,KH=1,KW=1)\n",
    "z_x, z_w = 128, 0\n",
    "b32 = np.array([0], dtype=np.int32)\n",
    "\n",
    "y32 = conv2d_int(xq, wq, z_x, z_w, b32, stride=1, padding=0)\n",
    "print(\"y32:\", y32)\n",
    "\n",
    "# escalas de ejemplo\n",
    "s_x, s_w, s_y = 0.02, 0.05, 0.04\n",
    "z_y, qmin, qmax = 10, 0, 255\n",
    "yq = requantize_int32(y32, s_x, s_w, s_y, z_y, qmin, qmax, out_dtype=np.uint8)\n",
    "yq_relu = np.maximum(yq, z_y)  # ReLU en cuantizado\n",
    "print(\"yq (antes ReLU):\", yq, \" yq_relu:\", yq_relu) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3b6a5",
   "metadata": {},
   "source": [
    "## 4) Per-tensor vs Per-channel\n",
    "Para pesos `per_channel`, `fit_weight_qparams` da `scale` vectorial por canal de salida y en `requantize_int32` se **difunde** como `(1, OC, 1, 1)` (conv) o `(1, Fout)` (lineal). Esto explica los reshape en §3.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
